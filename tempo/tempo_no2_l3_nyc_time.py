# ì¸¡ì • ì‹œê°ì„ nc íŒŒì¼ëª… ë‚´ ì‹œê°ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì½”ë“œ
# í´ë”ì˜ TEMPO_NO2_L3_V03_*.nc -> NYC BBOX ì¶”ì¶œ -> CSV ë³‘í•©
# time_utc ì€ "íŒŒì¼ëª…ì— ë“¤ì–´ìˆëŠ” ì‹œê°„"ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©

import os, re
import numpy as np
import pandas as pd
import xarray as xr
from glob import glob
from typing import Optional, Dict

# ===== ì‚¬ìš©ì ì„¤ì • =====
IN_DIR   = r""
OUT_CSV  = r""
BBOX     = (-74.3, 40.4, -73.6, 41.0)  # NYC
REMOVE_NEGATIVE = True

os.makedirs(os.path.dirname(OUT_CSV), exist_ok=True)

# íŒŒì¼ëª…ì—ì„œ ì‹œê°„ ë¬¸ìì—´ ì¶”ì¶œ: YYYYMMDDThhmm ë˜ëŠ” YYYYMMDDThhmmss (ë’¤ì— Z ìˆì„ ìˆ˜ë„)
TS_PAT = re.compile(r".*?(\d{8}T\d{4,6})(?:Z|_)?", re.IGNORECASE)

def time_from_filename(fname: str) -> pd.Timestamp:
    m = TS_PAT.match(fname)
    if not m:
        raise ValueError(f"íŒŒì¼ëª…ì—ì„œ ì‹œê°„ íŒ¨í„´ì„ ì°¾ì§€ ëª»í•¨: {fname}")
    stamp = m.group(1)  # e.g., 20250618T1900 or 20250618T190023
    fmt = "%Y%m%dT%H%M%S" if len(stamp) == 15 else "%Y%m%dT%H%M"
    return pd.to_datetime(stamp, format=fmt, utc=True)

def pick_var_by_candidates(dvars: Dict[str, xr.DataArray], candidates):
    """data_varsì—ì„œ í›„ë³´ëª…ì„ ìˆœì„œëŒ€ë¡œ ì°¾ì•„ ì²« ë§¤ì¹­ì„ ë°˜í™˜. ì—†ìœ¼ë©´ None"""
    lower_map = {k.lower(): k for k in dvars.keys()}
    for cand in candidates:
        if cand.lower() in lower_map:
            return lower_map[cand.lower()]
    return None

def find_no2_var(prod: xr.Dataset) -> str:
    # ì¼ë°˜ì ìœ¼ë¡œ TEMPO NO2 L3ëŠ” vertical_column_troposphere ì‚¬ìš©
    candidates = [
        "vertical_column_troposphere",
        "vertical_column",
        "no2_vertical_column",
        "no2_column",
    ]
    name = pick_var_by_candidates(prod.data_vars, candidates)
    if name:
        return name
    # fallback: 'no2' ë˜ëŠ” 'column' í¬í•¨ ë³€ìˆ˜ ì¤‘ ìœ ë ¥í•œ ê²ƒ ì„ íƒ
    for v in prod.data_vars:
        vlow = v.lower()
        if "no2" in vlow and ("column" in vlow or "vertical" in vlow):
            return v
    for v in prod.data_vars:
        if "column" in v.lower():
            return v
    raise RuntimeError(f"NO2 ë³€ìˆ˜ ìë™ íƒìƒ‰ ì‹¤íŒ¨: {list(prod.data_vars)}")

def find_cloud_fraction_var(prod: xr.Dataset) -> Optional[str]:
    # ë‹¤ì–‘í•œ ì´ë¦„ ê°€ëŠ¥ì„± ëŒ€ë¹„
    candidates = [
        "cloud_fraction",
        "scene_cloud_fraction",
        "cloudfrac",
        "cloud_fraction_troposphere",
        "cloud_fraction_total",
        "cloud_fraction_scene",
    ]
    name = pick_var_by_candidates(prod.data_vars, candidates)
    if name:
        return name
    # í­ë„“ì€ íœ´ë¦¬ìŠ¤í‹±: 'cloud'ì™€ 'fraction' ëª¨ë‘ í¬í•¨
    for v in prod.data_vars:
        vlow = v.lower()
        if ("cloud" in vlow) and ("fraction" in vlow):
            return v
    return None

def align_and_clean(da: xr.DataArray, lat, lon, lat_name, lon_name) -> xr.DataArray:
    # ì°¨ì› ì´ë¦„ ë§¤í•‘(y/x â†’ lat/lon)
    mapping = {}
    for d in da.dims:
        if da.sizes[d] == lat.size:
            mapping[d] = lat_name
        elif da.sizes[d] == lon.size:
            mapping[d] = lon_name
    da = da.rename(mapping).assign_coords({lat_name: lat, lon_name: lon})

    # ê²°ì¸¡/ìœ íš¨ë²”ìœ„/ìŒìˆ˜ ì²˜ë¦¬
    fill = da.encoding.get("_FillValue")
    if fill is not None:
        da = da.where(da != fill)

    valid_min = da.attrs.get("valid_min")
    valid_max = da.attrs.get("valid_max")
    if valid_min is not None:
        da = da.where(da >= float(valid_min))
    if valid_max is not None:
        da = da.where(da <= float(valid_max))

    da = da.where(np.isfinite(da))
    return da

def apply_bbox(da: xr.DataArray, lat_name: str, lon_name: str, bbox) -> xr.DataArray:
    if bbox is None:
        return da
    lon_min, lat_min, lon_max, lat_max = bbox
    return da.where(
        (da[lat_name] >= lat_min) & (da[lat_name] <= lat_max) &
        (da[lon_name] >= lon_min) & (da[lon_name] <= lon_max),
        drop=True
    )

def extract_one(nc_path: str) -> pd.DataFrame:
    # 1) ë£¨íŠ¸ì—ì„œ ìœ„ê²½ë„ ì¢Œí‘œ
    root = xr.open_dataset(nc_path, engine="netcdf4", decode_cf=True, mask_and_scale=True)
    lat_name = "latitude" if "latitude" in root.coords else ("lat" if "lat" in root.coords else None)
    lon_name = "longitude" if "longitude" in root.coords else ("lon" if "lon" in root.coords else None)
    if not lat_name or not lon_name:
        raise RuntimeError(f"[{os.path.basename(nc_path)}] ìœ„ê²½ë„ ì¢Œí‘œ ì—†ìŒ: {list(root.coords)}")
    lat, lon = root[lat_name], root[lon_name]

    # 2) /productì—ì„œ ê°’ ì½ê¸° (NO2 + cloud fraction)
    prod = xr.open_dataset(nc_path, group="product", engine="netcdf4", decode_cf=True, mask_and_scale=True)

    # --- NO2 ë³¸ë³€ìˆ˜ ---
    no2_var_name = find_no2_var(prod)
    no2_da = align_and_clean(prod[no2_var_name], lat, lon, lat_name, lon_name)
    if REMOVE_NEGATIVE:
        no2_da = no2_da.where(no2_da > 0)

    # --- Cloud fraction(ìˆìœ¼ë©´) ---
    cf_name = find_cloud_fraction_var(prod)
    cf_da = None
    if cf_name is not None:
        cf_da = align_and_clean(prod[cf_name], lat, lon, lat_name, lon_name)
        # ì¼ë°˜ì ìœ¼ë¡œ 0~1 ë²”ìœ„. ìœ íš¨ë²”ìœ„ê°€ ìˆìœ¼ë©´ ìœ„ì—ì„œ ì •ë¦¬ë¨.

    # 3) NYC BBOX
    no2_da = apply_bbox(no2_da, lat_name, lon_name, BBOX)
    if cf_da is not None:
        cf_da = apply_bbox(cf_da, lat_name, lon_name, BBOX)

    # 4) í‘œë¡œ ë³€í™˜
    df_no2 = no2_da.to_dataframe(name="no2").reset_index().dropna(subset=["no2"])
    # ğŸ”§ L3ì—ì„œ ë‚¨ëŠ” ë³´ì¡° ì°¨ì› 'time'ì´ ë¶™ìœ¼ë©´ ì œê±° (ì•ˆì „)
    if "time" in df_no2.columns:
        df_no2 = df_no2.drop(columns=["time"], errors="ignore")

    if cf_da is not None:
        df_cf = cf_da.to_dataframe(name="cloud_fraction").reset_index()
        if "time" in df_cf.columns:
            df_cf = df_cf.drop(columns=["time"], errors="ignore")
        # lat/lon ê¸°ì¤€ ë³‘í•©
        df = pd.merge(df_no2, df_cf[[lat_name, lon_name, "cloud_fraction"]],
                      on=[lat_name, lon_name], how="left")
    else:
        df = df_no2

    # 5) íŒŒì¼ëª… ê¸°ë°˜ ì‹œê°„ ì£¼ì… (ëª¨ë“  í–‰ ë™ì¼ â€” íŒŒì¼ë§ˆë‹¤ ë‹¤ë¦„)
    ts = time_from_filename(os.path.basename(nc_path))
    df["time_utc"] = ts.strftime("%Y-%m-%dT%H:%M:%SZ")

    # ë¶€ê°€ ì •ë³´
    units = no2_da.attrs.get("units")
    if units:
        df["no2_units"] = units
    if cf_da is not None and cf_da.attrs.get("units"):
        df["cloud_fraction_units"] = cf_da.attrs.get("units")

    df["source_file"] = os.path.basename(nc_path)

    # ì—´ ì •ë¦¬: time, lat, lon, no2, cloud_fraction(ì˜µì…˜), units, source_file ìˆœ
    base_cols = ["time_utc", lat_name, lon_name, "no2"]
    if "cloud_fraction" in df.columns:
        base_cols.append("cloud_fraction")
    if "no2_units" in df.columns:
        base_cols.append("no2_units")
    if "cloud_fraction_units" in df.columns:
        base_cols.append("cloud_fraction_units")
    base_cols.append("source_file")

    df = df[base_cols + [c for c in df.columns if c not in base_cols]]
    root.close(); prod.close()
    return df

def main():
    files = sorted(glob(os.path.join(IN_DIR, "*.nc")))
    if not files:
        raise FileNotFoundError(f".nc íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {IN_DIR}")

    out_list = []
    for p in files:
        try:
            out_list.append(extract_one(p))
            print(f"[OK] {os.path.basename(p)}")
        except Exception as e:
            print(f"[SKIP] {os.path.basename(p)} -> {e}")

    if not out_list:
        raise RuntimeError("ì²˜ë¦¬ ê°€ëŠ¥í•œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    out = pd.concat(out_list, ignore_index=True)
    out.to_csv(OUT_CSV, index=False, encoding="utf-8")
    print(f"\n ì™„ë£Œ: {OUT_CSV} (rows={len(out):,}, files={len(out_list)}/{len(files)})")

if __name__ == "__main__":
    main()
